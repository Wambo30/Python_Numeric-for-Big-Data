{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 10: Mehrschrittverfahren (MSV) und 2. Projektaufgabe\n",
    "\n",
    "Im folgenden geben wir einen kurzen Überblick über sogenannte *lineare Mehrschrittverfahren* zur numerischen Lösung von AWP und stellen die Adams-Verfahren und die BDF-Verfahren vor. Am Ende des Notebooks finden sie die 2. Projektaufgabe.\n",
    "\n",
    "Wir gehen hier \"Top-Down\" vor, d.h. wir formulieren zunächst die allgemeine Form eines linearen $k$-Schrittverfahren, in der geeignet zu wählende Koeffizienten vorkommen - ähnlich wie in den Butcher-Tableaus der Runge-Kutta-Verfahren.\n",
    "In einem zweiten Schritt werden dann diese Paramter geeignet gewählt, um gewünschte Konistenzordnungen der Verfahren zu erhalten. Unter geeigneten Voraussetzungen an das MSV (sogenannte Null-Stabilität) ist dann wieder die Konvergenzordnung gleich der Konsistenzordnung.\n",
    "\n",
    "Unser Augemerk liegt weniger auf einer weiteren Auflistung eines \"Zoos\" von Diskretisierungsverfahren für AWPen als vielmehr in dem methodischen Vorgehen, wie eine (parametrisierte) Verfahrensklasse definiert werden kann und dann innerhalb dieser Klasse durch zwei einfache Ideen (Modellierungen) systematisch und letztlich recht einfach  Verfahren mit hoher Konsistenzordnung hergeleitet werden können. Es ist diese \"Kreativität\", die angewandte Mathematik spannend macht. Zugegebenermaßen vollziehen wir hier die Kreativität anderer nach, aber auch das kann spannend sein. Unsere eigene Kreativität liegt dann in den kleineren und größeren Ideen bei der konkreten Umsetzung, bei der Auswahl von Verfahren, bei der Auswahl und Behandlung geeigneter Beispiele etc. . \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lineare MSV\n",
    "\n",
    "Ein $k$-Schritt Diskretisierungsverfahren zur appoximativen Lösung eines AWPs\n",
    "\n",
    "$$\n",
    "y^\\prime = f(t,y), \\quad y(t_0) = y^0\n",
    "$$\n",
    "\n",
    "ist definiert durch eine Verfahrensvorschrift für die Berechnung von $y^{j+k} \\approx y(t_{j+k})$  basierend auf den vorigen $k$ diskreten Approximationen $y^{j+l}$, $l=0, \\dots, k-1$: \n",
    "\n",
    "\\begin{align*}\n",
    "( y^0, \\dots , y^{k-1} ) & \\mapsto y^k \\\\\n",
    "( y^1, \\dots ,  y^{k} ) & \\mapsto y^{k+1} \\\\\n",
    "( y^j, \\dots ,  y^{j + k-1} ) & \\mapsto y^{j + k}\n",
    "\\end{align*}\n",
    "\n",
    "Beim Start des Verfahrens werden $k$ Startwerte \n",
    "$y^0, \\dots, y^{k-1}$ benötigt, die im Fall mit einen ESV berechnet werden müssen.\n",
    "\n",
    "Ein **lineares $k$-Schrittverfahren** hat die allgemeine Form\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\sum_{l=0}^k a_l y^{j+l} = h \\sum_{l=0} ^{k} b_l f(t_{j+l}, y^{j+1})\n",
    "}\n",
    "$$\n",
    "\n",
    "wobei $a_l, b_l$, $l=0, \\dots,  k$ fest gewählte Koeffizienten sind, die das MSV eindeutig festlegen. Es muss $a_k \\neq 0$ sein, da es sich um eine Berechnungsvorschrift für den einzigen neuen unbekannten Wert $y^{j+k}$ handelt. Außerdem gehen wir von äquistanden Zeitschritten $t_j = t_0 + j h$ aus.\n",
    "\n",
    "**Anmerkungen:**\n",
    "+ Falls $a_{k} = 1$ gewählt wird (was OBDA immer möglich wäre), ist\n",
    "\n",
    "$$\n",
    " y^{j+l} = - \\sum_{l=0}^{k-1} a_l y^{j+l}  + h \\sum_{l=0} ^{k} b_l f(t_{j+l}, y^{j+l})\n",
    "$$\n",
    "\n",
    "+ Die obige Verfahrensklasse ist - im Nachhinein betrachtet - das erste und einfachster, was einem für ein $k$-SChrittverfahren einfallen könnte.\n",
    "+ Das Verfahren ist implizit genau dann, wenn $b_k \\neq 0$\n",
    "+ Die Verfahrensvorschrift ist immer linear in den $f$-Auswertungen (im Gegensatz zu den Runge-Kutta-Verfahren)\n",
    "+ In jedem Zeitschritt kommt maximal eine neue $f$-Auswertung dazu, die übrigen  $k$ Stück sind vom letzten Zeitschritt bekannt, und können zwischengespeichert werden.\n",
    "+ $k = 1$, $a_0 = a_1 = 1$, $b_0 = 1$, $b_1 = 0$: Explizites Euler-Verfahren\n",
    "+ $k = 1$, $a_0 = a_1 = 1$, $b_0 = 0$, $b_1 = 1$: Implizites Euler-Verfahren\n",
    "+ **Aufgabe zum Verständnis:** Geben sie die Parameter für das Trapezverfahren an.\n",
    "+ Analog zum Vorgehen bei Runge-Kutta-Verfahren: Bestimme geeignete Koeffizienten $\\{a_l\\}$, $\\{b_l\\}$, damit der lokale Fehler eine möglichst hohe Fehlerordnung bezüglich der Zeitschrittweite $h$ hat.\n",
    "+ Zu untersuchen ist dann noch, ob, und unter welchen Voraussetzungen aus der Konsistenzordnung auch die Konvergenzordnung folgt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Herleitung geeigneter Koeffizienten\n",
    "\n",
    "Es gibt unter den linearen MSV zwei Verfahrensklassen, für die sich systematisch geeignete Koeffizienten aus einer Polynominterpolation herleiten lassen.\n",
    "\n",
    "#### Adams-Verfahren:\n",
    "**Ansatz und Idee:**\n",
    "\n",
    "\\begin{align*}\n",
    "y^{j+k} = y^{j+k - 1} +  &\\underbrace{ h \\sum_{l=0}^{k} b_l f(t_{j+l}, y^{j+l})} \\\\\n",
    "             &\\approx \\int_{t_{j+k-1}}^{t_{j+k}} f(s, y(s) ) \\, ds\n",
    "\\end{align*}\n",
    "\n",
    "Hier wurde also $a_k = 1$, $a_{k-1} = -1$, und $a_0 = \\cdots = a_{k-2} = 0$ gewählt. Die Herleitung geeigneter Koeffizienten $b_l$ erfolgt über die Integration eines Interpolationspolynoms $q(s)$ statt der (unbekannten) Funktion $g(s) = f(s, y(s))$.\n",
    " Falls $b_k = 0$ ist, ist das Verfahren explizit, sonst implizit.\n",
    "\n",
    "--- \n",
    "\n",
    "#### BDF-Verfahren \n",
    "(**b**ackward **d**ifferential **f**ormula).\n",
    "\n",
    "**Ansatz und Idee:**\n",
    "\\begin{align*}\n",
    "\\sum_{l=0}^k a_l y^{j+l} =  h f(t_{j+k}, y^{j+k}) , \\quad \\text{also}\n",
    "\\quad\n",
    "&\\underbrace{\\frac{\\sum_{l=0}^k a_l y^{j+l}}{h} } =   f(t_{j+k}, y^{j+k})\\\\\n",
    "& \\approx y^\\prime(t_{j+k}) =   f\\big( t_{j+k}, y(t_{j+k}) \\big)\n",
    "\\end{align*}\n",
    "\n",
    "Hier wurde also $b_k = 1$, $b_0 = b_1 = \\cdots = b_{k-1} = 0$ gesetzt. Eine Herleitung geeigneter Koeffizienten $a_l$ erfolgt durch numerische Differentiation, d.h. finite Differenzen Formeln. Diese ergeben sich durch die Ableitung eines Inpterpolationspolynoms $q(t)$ statt der unbekannten Funktion $y(t)$.\n",
    "\n",
    "Die BDF Verfahren sind alle implizit.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Adams-Verfahren\n",
    "\n",
    "Wir betrachten nur die expliziten Verfahren, also $b_k = 0$. \n",
    "\n",
    "**1. Schritt:** Berechne das Interpolationspolynom $q(t)$ vom Grad $k-1$, welches die folgenden $k$ Interpolationsbedingungen erfüllt:\n",
    "\n",
    "$$\n",
    "q(t_{j+l}) = f(t_{j+l}, y^{j+l}), \\quad l=0, \\dots, k-1\n",
    "$$\n",
    "\n",
    "Hierzu wird $q(t)$ in der Lagrange-Basis geschrieben (siehe unten bei BDF-Verfahren), also\n",
    "\n",
    "$$\n",
    "q(t) = \\sum_{l=0}^{k-1} f(t_{j+l}, y^{j+l}) L_l(t),\n",
    "$$\n",
    "\n",
    "**2. Schritt:**\n",
    "Berechne das Integral\n",
    "\n",
    "$$\n",
    "\\int_{t_{j+k - 1}}^{t_{j+k}} q(t) \\, dt = h \\sum_{l=0}^{k-1} b_l f(t_{j+l}, y^{j+l}), \\quad \\boxed{b_l = \\frac{1}{h} \\int_{t_{j+k - 1}}^{t_{j+k}} L_l(t) \\, dt }\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**3. Schritt:** Da das Interpolationspoylnom $q(t)$ eine gute Approximation von $f(s, y(s))$ in der Nähe von $t_{j+k}$ ist, postulieren wird\n",
    "\n",
    "$$\n",
    "y^{j+k} = y^{j+k-1} + \\int_{t_{j+k - 1}}^{t_{j+k}} q(t) \\, dt =  y^{j+k-1} + h \\sum_{l=0}^{k-1} b_l f(t_{j+l}, y^{j+l})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. BDF - Verfahren\n",
    "\n",
    "Wir betrachten einen Zeitschritt zur Berechnung von $y^{j+k}$ bei gegebenen $y^j, \\dots, y^{j + k - 1}$.\n",
    "\n",
    "**1. Schritt:** Leite eine Formel her für das Interpolationspolynom $q(t)$ vom Grad $k$ mit den $k+1$ Interpolationsbedingungen\n",
    "\n",
    "$$\n",
    "q(t_{j+l}) = y^{j+l}, \\quad l=0, \\dots, k .\n",
    "$$\n",
    "\n",
    "Das Polynom $q(t)$ soll dann $y(t)$ in der Nähe von $t_{j+k}$ gut approximieren. In Numerik 2 hatten wir Formeln für den Approximationsfehler hergeleitet, abhängig vom Abstand $h$ der Knoten $t_{j+l}$. \n",
    "\n",
    "Die Berechnung von $q$ geschieht am Besten in der Lagrangebasis:\n",
    "\n",
    "$$\n",
    "q(t) = \\sum_{l=0}^k y^{j+l} L_l(t), \\qquad L_l(t) = \\prod_{i=0, i\\neq l}^k \\frac{t - t_{j+i}}{t_l - t_{j+i}}\n",
    "$$\n",
    "\n",
    "**2. Schritt:** Wir berechnen die Ableitung $q^\\prime(t)$, dann ist $q^\\prime(t_{j+k}) \\approx y^\\prime(t_{j+k})$ und ist eine Linearkombination der $y^{j+l}$, also immer von der Form\n",
    "\n",
    "$$\n",
    " q^\\prime(t_{j+k}) = \\sum_{l=0}^k \\frac{a_l}{h} y^{j+l}, \\quad \\boxed{ a_l = h L_l^\\prime(t_{j+k}) }\n",
    "$$\n",
    "\n",
    "**3. Schritt:** Wir postulieren $q^\\prime(t_{j+k}) = f(t_{j+k}, y^{j+k})$, also\n",
    "\n",
    "$$\n",
    "\\sum_{l=0}^k a_l y^{j+l} =  h f(t_{j+k}, y^{j+k}).\n",
    "$$\n",
    "\n",
    "--- \n",
    "\n",
    "### Beispiel: Berechnung der Koeffizienten für  BDF2:\n",
    "Für $k=2$ ergibt sich:\n",
    "\n",
    "\\begin{align*}\n",
    "q(t) &= y^j L_0(t) + y^{j+1} L_1(t) + y^{j+2} L_2 (t) \\\\\n",
    "q^\\prime(t_{j+2}) &= y^j \\underbrace{L^\\prime_0(t_{j+2})}_{a_0/h} \n",
    "+ y^{j+1} \\underbrace{L^\\prime_1(t_{j+2})}_{a_1 / h} \n",
    "+ y^{j+2} \\underbrace{L^\\prime_2 (t_{j+2})}_{a_2/ h}\n",
    "\\end{align*}\n",
    "\n",
    "mit \n",
    "\n",
    "\\begin{align*}\n",
    "L_0(t) &= \\frac{ (t - t_{j+1}) (t - t_{j+2}) }{ (t_j - t_{j+1}) (t_j - t_{j+2}) } = \\frac{ (t - t_{j+1}) (t - t_{j+2}) }{ 2 h^2 } \\\\\n",
    "L^\\prime_0(t) &= \\frac{ (t - t_{j+1})  }{ 2 h^2 }  \\frac{ (t - t_{j+2})  }{ 2 h^2 } \\\\\n",
    "L^\\prime_0(t_{j+2}) &= \\frac{ (t_{j+2} - t_{j+1})  }{ 2 h^2 } + 0 =  \\frac{h}{2 h^2} = \\underbrace{\\frac{1}{2}}_{ = a_0} \\frac{1}{h}\n",
    "\\end{align*}\n",
    "\n",
    "**Aufgabe:** Ergänzen sie die Rechnung für $L_1$ und $L_2$, um das folgende Ergebnis zu bestätigen:\n",
    "\n",
    "$$\n",
    "q^\\prime(t_{j+2}) = \\big( \\frac{1}{2} y^j - 2 y^{j+1} + \\frac{3}{2} y^{j+2} \\big) / h.\n",
    "$$\n",
    "\n",
    "Also ist $a_0 = 1/2$, $a_1 = -2$, $a_2 = 3/2$ und die BDF2-Verfahrensvorschrift lautet:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{1}{2} y^j - 2 y^{y+1} + \\frac{3}{2} y^{j+2} = hf(t_{j+2}, y^{j+2})\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Die Berechnung für größere $k$ verläuft völlig analog, wenn auch etwas aufwändiger. Die Koeffizienten finden Sie in (fast) jedem Buch zur numerischen Lösung von AWPen, siehe auch [wikipedia][ttps://de.wikipedia.org/wiki/BDF-Verfahren].\n",
    "\n",
    "Aus den Approximationseigenschaften des Interpolationspolynoms folgt, dass das BDF-k - Verfahren die Konsistenzordnung $p=k$ hat. Des weiteren gilt, dass bis $k = 6$ alle BDF-k Verfahren*nullstabil* sind (das nur als Stichwort an dieser Stelle), und damit auch die Konvergenzordnung  $p = k$ besitzen (siehe z.B. [Deufelhard, Bornemann]).\n",
    "\n",
    "----------------\n",
    "\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Projektaufgabe\n",
    "\n",
    "### Aufgabe 1: 10 Punkte\n",
    "Implementieren Sie das BDF2-Verfahren in ihrem Python-Modul `odesolver.py`. Eine geeignete Signatur ist z.B.    \n",
    "``` bdf2(f, t_span, y0, t_eval=None,  jac=None) ```.\n",
    "+ Wählen Sie zur Berechnung des zweiten Startwertes $y^1$ ein geeignetes Einschrittverfahren derselben Ordnung.\n",
    "+ Neben der diskreten Lösung soll auch die in jedem Zeitschritt benötigte Anzahl an Iterationen im Newton-Verfahren zurückgegeben werden.\n",
    "+ Falls die Jakobi-Matrix von $f$ (bez. $y$) nicht als Funktion übergeben wird, soll diese mit finiten Differenzen approximiert werden, siehe Hinweise im Notebook 8.\n",
    "+ Falls kein Vektor 't_eval' übergeben wird, soll das Zeitintervall $[t_0, t_f]$ in 1000 Zeitschritte zerlegt werden.\n",
    "+ Sie können auch Werte für die Toleranz und maximale Anzahl an Iteration für das Newtonverfahren übergeben.\n",
    "+ Testen Sie die korrekte Funktionalität an einem skalaren und an einem vektorwertigen AWP.\n",
    "\n",
    "**Hinweise zur Implementierung:**\n",
    "+ Ich empfehle Ihnen, erst das implizite Euler-Verfahren zu implementieren bzw. diese Implementierung in allen Dataills zu verstehen.\n",
    "+ Stellen Sie dann zunächst das für das BDF2-Verfahren zu lösende Nullstellenproblem auf und setzen Sie das Verfahren in Python um - zunächst mit einer übergebenen Funktion für die Jakobi-Matrix von $f$ (bezüglich y).\n",
    "+ Wenn das Verfahren fehlerfrei läuft, dann erweiteren Sie mit einer Finiten-Differenzen-Approximation der Jakobi-Matrix. Dies sollten Sie dann auf jeden Fall mit einem nichtlinearen vektorwertigen AWP testen.\n",
    "\n",
    "\n",
    "### Aufgabe 2: 15 Punkte\n",
    "Beschreiben und untersuchen Sie die Eigenschaften des BDF2-Verfahren (auch mit geeigneten grafischen Darstellungen) in einem Projektbericht in Form eines Jupyter-Notebooks, in dem auch einige Code-Abschnitte zum weiteren Experimentieren enthalten sind. Dieses soll für sich alleine verständlich sein und sowohl Theorie als auch Erklärungen zur Implementierung und Diskussion von Auswertungen enthalten und insgesamt interessant zu lesen sein. Im Folgenden finden Sie einige Anregungen:\n",
    "\n",
    "+ Wählen Sie einen Titel für ihren Projektbericht.\n",
    "+ Beginnen Sie mit einem kurzen Abstract: Was ist das Thema, was soll behandelt und untersucht werden\n",
    "+ Gliedern Sie das Notebook in sinnvolle Abschnitte mit Überschriften. Nicht \"Aufgabe 1, Aufgabe 2\"... . Die Aufgabenstellung soll/muss nicht wiederholt werden. Dieses hier vorliegende Notebook soll nicht Teil des Projektberichtes sein. Wenn Sie Formeln aus diesem Notebook benötigen, können sie diese kopieren.\n",
    "+ Erläutern sie kurz die BDF2-Verfahrensvorschrift, und woher sie kommt.\n",
    "+ Leiten Sie das in jedem Zeitschritt zu lösende Nullstellenproblem her.\n",
    "+ Untersuchen Sie, wieviele Newton-Iterationen in jedem ZEitschritt benötigt werden.\n",
    "+ Bestätigen sie experimentell, dass das Verfahren die Konvergenzordnung $p=2$ hat. Hier könnten sie auch mit einem Verfahren der Ordnung $p=1$ vergleichen (z.B. doppeltlogarithmischer Plot des globalen Fehlers über $h$).\n",
    "+ Betrachten Sie einige Beispiele\n",
    "+ Sie können auch Vergleiche mit anderen bereits implementierten Diskretisierungsverfahren durchführen und diskutieren.\n",
    "+ Diskutieren sie das Anwendungsbeispiel des Van der Pol Oszillators.\n",
    "+ Bitte geben sie alle verwendeten Quellen an.\n",
    "\n",
    "Seien sie gerne etwas kreativ. Sie müssen nicht \"stur\" alle obigen Punkte abarbeiten. Vielleicht haben Sie auch andere Ideen. In dem Notebook soll ein interessanter Einblick in die Diskretierung von AWPen mit einem guten impliziten Verfahren - dem BDF2-Verfahren - gegeben werden. Es kommen viele Konzepte der numerischen und der angewandten Mathematik vor: \n",
    "+ Numerische Differentiation, Problem der Auslöschung bei Subtraktion fast gleichgroßer Zahlen (Stabilität eines Algothmus)\n",
    "+ Polynominterpolation (Herleitung BDF2)\n",
    "+ Newtonverfahren zur Lösung nichtlinearer Gleichungssysteme, Abbruchbedingung und approximative Jakobi-Matrix\n",
    "+ Lösung linearer Gleichungssysteme (in jedem Newtonschritt)\n",
    "+ Diskretisierungsverfahren zur Lösung von AWPen, Konvergenzordnung.\n",
    "+ Asymptotisch stabile Grenzzyklen eines AWPs\n",
    "+ Steife AWPe\n",
    "+ ... \n",
    "\n",
    "**Es ist wahrscheinlich ihre letzte Numerik-Projektaufgabe :-). Zögern Sie also nicht, Alles zu geben ... .**\n",
    "\n",
    "---\n",
    "\n",
    "Das Projekt kann in einem Team zu zweit bearbeitet und erstellt werden.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendungsbeispiel: Van der Pol Oszillator\n",
    "Das folgende Anfangswertproblem, der sogenannte *Van der Pol-Oszillator*, ist eines der klassischen Testbeispiele für numerische Lösungsverfahren von steifen Problemen \n",
    "\n",
    "\\begin{equation*}\n",
    "\ty^{\\prime\\prime} = \\mu(1-y^2)y^\\prime - y, \\quad t \\in [0,T], \\quad y(0) = 2, \\quad y^\\prime(0) = 0.\n",
    "\\end{equation*}\n",
    "\n",
    "Dieser nichtlineare Oszillator hat dynamisch sehr interessante Eigenschaften, die von dem Wert des Parameters $\\mu$ abhängen. Er wurde z.B. zur Modellierung von oszillierenden biologischen Systemen (Herzschläge, Neuronen im Gehirn) verwendet. Testen Sie das Verhalten für $\\mu > 0$ und unterschiedliche Anfangswerte. Was ist hier qualitativ anders als bei dem linearen Oszillator ($\\mu = 0$) ? Beobachten Sie, dass das System seine Anfangsbedingung \"vergißt\", schon für ein beliebig kleines $\\mu$, und sich einem Grenzzyklus annähert (als Trajektorie im Phasenraum). \n",
    "\t\n",
    "Seine Prominenz als Testfall für AWP-Löser verdankt der Van der Pols Oszillator der Tatsache, \n",
    " dass man durch Wahl des Parameters $\\mu$ die Steifheit des Problems nahezu beliebig verändern kann. Für $\\mu = 0$ erhält man den harmonischen Oszillator (linear, rein komplexe Eigenwerte), für moderate Größen $\\mu \\sim 1$ ist das Problem nicht steif, für große $\\mu$ wird das Problem extrem steif. Eigentlich wäre ein implizites Lösungsverfahren mit adaptiver Schrittweitensteuerung am Besten geeignet. Wir belassen es in dieser Projektaufgabe bei der Anwendung eines impliziten Diskretisierungsverfahrens mit Konstistenzordnung $p=2$.\n",
    "\n",
    " \n",
    "Betrachten Sie zum Beispiel die folgenden Testfälle\n",
    "\n",
    "  \n",
    "\n",
    " $\\mu$ |  0     | 1      | 10    | 100     \n",
    " ------ | ------ | ------ | ----- | ----- \n",
    " $T$   |  20    | 20     | 50    | 500           \n",
    "\n",
    "Versuchen Sie auch, die Testfälle mit Ihren selbstimplementierten expliziten Lösern approximativ zu lösen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
